{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Part III - Transactions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import os\n",
    "import dask \n",
    "from datetime import datetime, timedelta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Get data from API**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO : \n",
    "\n",
    "- Run la cell en dessous \n",
    "- Avant, il faut aller [ici](https://docs.coinapi.io/), rentrer son adresse mail et clicker sur `get a free api key`\n",
    "- Copier coller la clé dans un fichier dans le directory du notebook : nom du ficher --> `path_file_API`\n",
    "- Aller dans le fichier `periods_API.txt`\n",
    "- Choisir l'index (0,7,14,...) --> dans `index`\n",
    "\n",
    "- Joao : Tu peux faire de 30 à 35 (des fois ça bug, donc va dans periods_API.txt, supprime les colonnes déjà Ok et retente avec une autre clé api)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_time_periods() : \n",
    "    # Define the start and end dates\n",
    "    start_date = datetime(2021, 1, 1)\n",
    "    end_date = datetime(2021, 9, 1)\n",
    "\n",
    "    # Generate a list of dates\n",
    "    date_list = [start_date + timedelta(days=x) for x in range((end_date - start_date).days + 1)]\n",
    "    datetime_strings = [dt.strftime('%Y-%m-%d') for dt in date_list]\n",
    "    \n",
    "    #Divide into slots of 7 (we can only make 10 calls per day)\n",
    "    slot_size = 7\n",
    "    date_slots = [datetime_strings[i:i+slot_size] for i in range(0, len(datetime_strings), slot_size)]\n",
    "    \n",
    "    with open(\"data/periods_API.txt\", \"w\") as file : \n",
    "        for i in range(0, len(datetime_strings), slot_size) :\n",
    "            data = str(i) + \" : \" + \" \".join(datetime_strings[i:i+slot_size])\n",
    "            file.write(data + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve API key\n",
    "def retrieve_api_key(name_file) : \n",
    "    api_key = None\n",
    "    with open(name_file) as file:\n",
    "        api_key = file.readline().strip()\n",
    "    return api_key\n",
    "\n",
    "\n",
    "# Retrieve historical data on Trades\n",
    "def get_historical_data(type, headers, index, day, save_dir) :\n",
    "    \n",
    "    parameters = {  \n",
    "        \"symbol_id\": \"BITSTAMP_SPOT_BTC_USD\",\n",
    "        \"time_start\" : day+'T00:00',\n",
    "        \"time_end\" : day+'T23:59',\n",
    "        \"limit\" : 100000, \n",
    "    }\n",
    "    r = requests.get(f\"https://rest.coinapi.io/v1/{type}/BITSTAMP_SPOT_BTC_USD/history\", \n",
    "                     headers=headers, params=parameters)\n",
    "\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if r.status_code == 200:\n",
    "        # Parse and print the trade data\n",
    "        data = r.json()\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        #Save as csv \n",
    "        if not os.path.isdir(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "\n",
    "        name_file = str(index) + \"_\" + day\n",
    "        df.to_parquet(save_dir+name_file, use_deprecated_int96_timestamps=True, compression=\"brotli\")\n",
    "\n",
    "    else:\n",
    "        # Print an error message if the request was unsuccessful\n",
    "        print(f\"Error: {r.status_code} - {r.text}\")\n",
    "\n",
    "def main_get_historical_data(type, path_file_API, path_file_periods, index) : \n",
    "    api_key = retrieve_api_key(path_file_API)\n",
    "    headers = {\"X-CoinAPI-Key\": api_key}\n",
    "\n",
    "    days_list = None\n",
    "    #Open the file and get the list of index to scrap (based on index)\n",
    "    with open(path_file_periods) as file : \n",
    "        lines = file.readlines()\n",
    "        for line in lines : \n",
    "            if line.split(\":\")[0].strip() == str(index) :\n",
    "                days_list = line.split(\":\")[1][1:-1].split(\" \")\n",
    "    \n",
    "    for day in days_list : \n",
    "        get_historical_data(type, headers, index, day, save_dir = \"data/raw/trades/\")\n",
    "\n",
    "\n",
    "#To call every day \n",
    "def main_get_historical_trades(path_file_API, path_file_periods, index) : \n",
    "    main_get_historical_data(\"trades\", path_file_API, path_file_periods, index)\n",
    "\n",
    "def main_get_historical_quotes(path_file_API, path_file_periods, index) : \n",
    "    main_get_historical_data(\"quotes\", path_file_API, path_file_periods, index)\n",
    "\n",
    "\n",
    "#main_get_historical_trades(\"API_key_affolter.txt\", \"data/periods_API.txt\", 175)\n",
    "#main_get_historical_trades(\"API_key_ben.txt\", \"data/periods_API.txt\", 182)\n",
    "#main_get_historical_trades(\"API_key_epfl.txt\", \"data/periods_API.txt\", 189)\n",
    "#main_get_historical_trades(\"API_key_joanne.txt\", \"data/periods_API.txt\", 196)\n",
    "main_get_historical_trades(\"API_key_reve.txt\", \"data/periods_API.txt\", 203)\n",
    "main_get_historical_trades(\"API_key_data.txt\", \"data/periods_API.txt\", 210)\n",
    "main_get_historical_trades(\"API_key_benProut.txt\", \"data/periods_API.txt\", 217)\n",
    "main_get_historical_trades(\"API_key_anne.txt\", \"data/periods_API.txt\", 224)\n",
    "main_get_historical_trades(\"API_key_benjiplayer.txt\", \"data/periods_API.txt\", 231)\n",
    "main_get_historical_trades(\"API_key_toto.txt\", \"data/periods_API.txt\", 238)\n",
    "#main_get_historical_trades(\"API_key_benj.txt\", \"data/periods_API.txt\", 133)\n",
    "#main_get_historical_trades(\"API_key_spoteamfy.txt\", \"data/periods_API.txt\", 140)\n",
    "#main_get_historical_trades(\"API_key_toto_reve.txt\", \"data/periods_API.txt\", 140)\n",
    "#main_get_historical_trades(\"API_key_bene.txt\", \"data/periods_API.txt\", 147)\n",
    "#main_get_historical_trades(\"API_key_anne_reve.txt\", \"data/periods_API.txt\", 154)\n",
    "#main_get_historical_trades(\"API_key_bene3.txt\", \"data/periods_API.txt\", 168)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['28_2021-01-29', '49_2021-02-23', '7_2021-01-08', '7_2021-01-11']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check which files don't have all data collected \n",
    "\n",
    "import glob \n",
    "\n",
    "allfiles = glob.glob(\"data/raw/trades/*\")\n",
    "\n",
    "not_all_transactions = []\n",
    "for file in allfiles : \n",
    "    df = pd.read_parquet(file)\n",
    "    if len(df) == 100000 :\n",
    "        name_file = file.split(\"\\\\\")[1]\n",
    "        not_all_transactions.append(name_file)\n",
    "\n",
    "not_all_transactions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adaexam2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
